{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Part 4.2: Sentiment Analysis with Amazon Reviews Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:\\\\Users\\\\wmj51\\\\Desktop\\\\python')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from textblob import TextBlob\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vaderSentiment\n",
    "\n",
    "As Vader has included proper handling of sentences (shown below), I will clean text with the possible noise elements (e.g., @mention,URLs and www.). \n",
    "\n",
    "- typical negations (e.g., \"not good\")\n",
    "- use of contractions as negations (e.g., \"wasn't very good\")\n",
    "- conventional use of punctuation to signal increased sentiment intensity (e.g., \"Good!!!\")\n",
    "- conventional use of word-shape to signal emphasis (e.g., using ALL CAPS for words/phrases)\n",
    "- using degree modifiers to alter sentiment intensity (e.g., intensity boosters such as \"very\" and intensity dampeners such as \"kind of\")\n",
    "- understanding many sentiment-laden slang words (e.g., 'sux')\n",
    "- understanding many sentiment-laden slang words as modifiers such as 'uber' or 'friggin' or 'kinda'\n",
    "- understanding many sentiment-laden emoticons such as :) and :D\n",
    "- translating utf-8 encoded emojis such as üíò and üíã and üòÅ\n",
    "- understanding sentiment-laden initialisms and acronyms (for example: 'lol')\n",
    "\n",
    "The possible noise elements that should be removed as follows:\n",
    "- URLs/www.: URLs and hyperlinks in text data like comments, reviews, and tweets should be removed\n",
    "- @mention: same with emoticons, even though it carries some information, for sentiment analysis purpose, this can be ignored\n",
    "- HTML: data contains html entities such as &amp in the text field "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_amazon_shortreview.csv', index_col = 0, encoding = \"ISO-8859-1\")\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "import string\n",
    "import HTMLParser\n",
    "html_parser = HTMLParser.HTMLParser()\n",
    "import re\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "split_dic = {\"cause\": \"because\", \"could've\": \"could have\", \n",
    "             \"he'd\": \"he would\", \"he'd've\": \"he would have\", \"he'll\": \"he will\", \n",
    "             \"he'll've\": \"he will have\", \"he's\": \"he is\", \"how'd\": \"how did\", \n",
    "             \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \n",
    "             \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \n",
    "             \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \n",
    "             \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\", \n",
    "             \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \n",
    "             \"it'd\": \"it would\", \"it'd've\": \"it would have\", \n",
    "             \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \n",
    "             \"let's\": \"let us\", \"ma'am\": \"madam\", \n",
    "             \"might've\": \"might have\",\n",
    "             \"must've\": \"must have\",\n",
    "             \"o'clock\": \"of the clock\", \n",
    "             \"she'd\": \"she would\", \n",
    "             \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \n",
    "             \"she's\": \"she is\", \"should've\": \"should have\", \n",
    "             \"so've\": \"so have\",\"so's\": \"so as\", \n",
    "             \"this's\": \"this is\",\n",
    "             \"that'd\": \"that would\", \"that'd've\": \"that would have\",\"that's\": \"that is\", \n",
    "             \"there'd\": \"there would\", \"there'd've\": \"there would have\",\"there's\": \"there is\", \n",
    "             \"here's\": \"here is\",\n",
    "             \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \n",
    "             \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\",\n",
    "             \"to've\": \"to have\", \"we'd\": \"we would\", \n",
    "             \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \n",
    "             \"we're\": \"we are\", \"we've\": \"we have\", \n",
    "             \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \n",
    "             \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \n",
    "             \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \n",
    "             \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \n",
    "             \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \n",
    "             \"why've\": \"why have\", \"will've\": \"will have\", \n",
    "             \"would've\": \"would have\", \n",
    "             \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "             \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "             \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \n",
    "             \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }\n",
    "\n",
    "pat1 = r'@[\\w_]+' # @-mention\n",
    "pat2 = r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+' # URLs\n",
    "pat5 = r'www.[^ ]+' # additions to URLs, texts with 'www..'\n",
    "combined_pat = r'|'.join((pat1, pat2, pat5))\n",
    "\n",
    "split_pattern = re.compile(r'\\b(' + '|'.join(split_dic.keys()) + r')\\b')\n",
    "\n",
    "def tweet_cleaner(demo):\n",
    "    soup = BeautifulSoup(demo, 'lxml') # HTML\n",
    "    souped = soup.get_text()\n",
    "    stripped = re.sub(combined_pat, '', souped)\n",
    "    split_handled = split_pattern.sub(lambda x: split_dic[x.group()], stripped)\n",
    "\n",
    "    return split_handled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"...\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"....\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"..........\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \".\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"....................................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"........\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \".............\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \".......\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"..........................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \".....\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \".........\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"/\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B000BQQMJQ/ref=cm_cr_ryp_sol_prd_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"..\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"......\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \". . .\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"............................................................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"......................................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \".........................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"..................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"....................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \".................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"... ...\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"...........\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.vidnet.com\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.geocities.com/Athens/7887/midnightclub.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"....................................................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"................................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/1440036020/ref=cm_cr_rev_prod_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B000NNJUNW/ref=cm_cr_rev_prod_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \".......................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \". . . . . . . . . . . . . . . . . .\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B000GC1YAC/ref=cm_cr_rev_prod_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"..//..\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.geocities.com/ada_pr/AmrDiab\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \". . . . .\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B0006N07V8/ref=cm_cr_rev_prod_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"........................................................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"............\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"..............\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"./\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"...............\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"...................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.infidels.org/library/modern/alex_matulich/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \".......................................................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.thornewoodcastle.com/movie.htm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/0800141660/ref=cm_cr_ryp_prd_ttl_sol_6\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B0002Z82XA/ref=cm_cr_rev_prod_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B000JL69XC/ref=cm_cr_rev_prod_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"......................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"..............................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"... ... ...\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://mediamatters.org/items/200604240012\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.amazon.com/gp/aw/d/1563922134/ref=aw_cr_item_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.infidels.org/infidels/products/books/atheism.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"...........................................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"........................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B0000E2DJD/ref=cm_cr_rev_prod_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.infidels.org/infidels/products/books/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.amazon.com/Flo-Go-08339-SuperFlo-Pump/dp/B000JFI882/ref=cm_cr_pr_product_top\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://masada2000.org\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B000DZF41W/ref=cm_cr_rev_prod_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B0000BYACO/ref=cm_cr_ryp_prd_ttl_sol_91\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B00004TS3P/ref=cm_cr_rev_prod_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/0958454981/ref=cm_cr_rev_prod_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.feralcheryl.com.au/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['clean_text'] = [tweet_cleaner(t) for t in df.text]\n",
    "df.to_csv('train_amazon_shortreview_clean.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting thresholds for classifying sentences as either positive, neutral, or negative, the results can be found as follows: \n",
    "\n",
    "- 'Compound range from (-0.15, 0.15) | neu >= 0.55 Accuracy Score : 87.09% (shortreview.csv) 89.62% (longreview.csv)\n",
    "- 'Compound range from (-0.25, 0.25) | neu >= 0.55 Accuracy Score : 88.34% (shortreview.csv) 90.15% (longreview.csv)\n",
    "- 'Compound range from (-0.35, 0.35) | neu >= 0.55 Accuracy Score : 89.58% (shortreview.csv) 90.69% (longreview.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I am reading a lot of reviews saying that this...</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.8481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>This soundtrack is my favorite music of all ti...</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.9847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I truly like this soundtrack and I enjoy video...</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.9753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>If you have played the game, you know how divi...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.9781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I am quite sure any of you actually taking the...</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.9873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                         clean_text    neg    neu  \\\n",
       "0       1  I am reading a lot of reviews saying that this...  0.019  0.851   \n",
       "1       1  This soundtrack is my favorite music of all ti...  0.040  0.697   \n",
       "2       1  I truly like this soundtrack and I enjoy video...  0.092  0.631   \n",
       "3       1  If you have played the game, you know how divi...  0.000  0.725   \n",
       "4       1  I am quite sure any of you actually taking the...  0.015  0.752   \n",
       "\n",
       "     pos  compound  \n",
       "0  0.129    0.8481  \n",
       "1  0.263    0.9847  \n",
       "2  0.278    0.9753  \n",
       "3  0.275    0.9781  \n",
       "4  0.233    0.9873  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "df = pd.read_csv('train_amazon_longreview_vader.csv', index_col = 0)\n",
    "df.drop(columns = ['Unnamed: 0.1'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['com'] = df['compound']\n",
    "\n",
    "df = df.drop(df[(df['compound'] >= -0.15) & (df['compound'] <= 0.15)].index)\n",
    "df.loc[df['compound'] > 0.15, 'compound'] = 1\n",
    "df.loc[df['compound'] < -0.15, 'compound'] = 0\n",
    "df = df.drop(df[df['neu'] >=0.55].index)\n",
    "df['cheating0.15'] = np.where(df['target'] != df['compound'], 'yes', 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compound range from (-0.15, 0.15) | neu >= 0.55 Accuracy Score : 89.62%\n"
     ]
    }
   ],
   "source": [
    "print \"Compound range from (-0.15, 0.15) | neu >= 0.55 Accuracy Score : {0:.2f}%\".format((1 - (len(df.loc[df['cheating0.15'] == 'yes']) / len(df)))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIWC \n",
    "\n",
    "The Tone variable puts the two dimensions (positive emotion and negative emotion dimensions) into a single summary variable Cohn, Mehl, & Pennebaker, 2004). The algorithm is built so that the higher the number, the more positive the tone. Numbers below 50 suggest a more negative emotional tone. The accuracy results can be found as follows: \n",
    "\n",
    "- Tone range from (50, 50) | Accuracy Score : 68.01% (shortreview.csv) 67.29& (longreview.csv)\n",
    "- Tone range from (45, 55) | Accuracy Score : 68.01% (shortreview.csv) 68.18% (longreview.csv)\n",
    "- Tone range from (40, 60) | Accuracy Score : 68.01% (shortreview.csv) 69.06% (longreview.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>tone</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I am reading a lot of reviews saying that this...</td>\n",
       "      <td>65.65</td>\n",
       "      <td>3.16</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>This soundtrack is my favorite music of all ti...</td>\n",
       "      <td>99.00</td>\n",
       "      <td>9.92</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I truly like this soundtrack and I enjoy video...</td>\n",
       "      <td>99.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>If you have played the game, you know how divi...</td>\n",
       "      <td>99.00</td>\n",
       "      <td>7.59</td>\n",
       "      <td>1.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I am quite sure any of you actually taking the...</td>\n",
       "      <td>99.00</td>\n",
       "      <td>6.38</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               text   tone   pos   neg\n",
       "0      1  I am reading a lot of reviews saying that this...  65.65  3.16  1.05\n",
       "1      1  This soundtrack is my favorite music of all ti...  99.00  9.92  0.76\n",
       "2      1  I truly like this soundtrack and I enjoy video...  99.00  8.40  0.84\n",
       "3      1  If you have played the game, you know how divi...  99.00  7.59  1.27\n",
       "4      1  I am quite sure any of you actually taking the...  99.00  6.38  0.00"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_amazon_longreview_LIWC.csv', index_col = 0)\n",
    "df = df.iloc[1:]\n",
    "df.columns = ['target','text','tone','pos','neg']\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[(df['tone'] >= 40) & (df['tone'] <= 60)].index)\n",
    "df.loc[df['tone'] > 60, 'tone'] = 'pos'\n",
    "df.loc[df['tone'] < 40, 'tone'] = 'neg'\n",
    "df['tone'] = df['tone'].map({'pos':1, 'neg':0})\n",
    "df['cheating'] = np.where(df['target'] != df['tone'], 'yes', 'no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\numpy\\lib\\arraysetops.py:466: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has total 3527815 entries with 50.00% negative, 50.00% positive\n",
      "Test set has total 71997 entries with 50.15% negative, 49.85% positive\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train_amazon_shortreview_clean.csv', index_col = 0, encoding = \"ISO-8859-1\")\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "x = df.clean_text\n",
    "y = df.target\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "SEED = 2000\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.02, random_state=SEED)\n",
    "\n",
    "print (\"Train set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(x_train),\n",
    "                                                                             (len(x_train[y_train == 0]) / (len(x_train)*1.))*100,\n",
    "                                                                            (len(x_train[y_train == 1]) / (len(x_train)*1.))*100))\n",
    "print (\"Test set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(x_test),\n",
    "                                                                             (len(x_test[y_test == 0]) / (len(x_test)*1.))*100,\n",
    "                                                                            (len(x_test[y_test == 1]) / (len(x_test)*1.))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from time import time\n",
    "\n",
    "def accuracy_summary(pipeline, x_train, y_train, x_test, y_test):\n",
    "    if len(x_test[y_test == 0]) / (len(x_test)*1.) > 0.5:\n",
    "        null_accuracy = len(x_test[y_test == 0]) / (len(x_test)*1.)\n",
    "    else:\n",
    "        null_accuracy = 1. - (len(x_test[y_test == 0]) / (len(x_test)*1.))\n",
    "    t0 = time()\n",
    "    sentiment_fit = pipeline.fit(x_train, y_train)\n",
    "    y_pred = sentiment_fit.predict(x_test)\n",
    "    train_test_time = time() - t0\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print (\"null accuracy: {0:.2f}%\".format(null_accuracy*100))\n",
    "    print (\"accuracy score: {0:.2f}%\".format(accuracy*100))\n",
    "    if accuracy > null_accuracy:\n",
    "        print (\"model is {0:.2f}% more accurate than null accuracy\".format((accuracy-null_accuracy)*100))\n",
    "    elif accuracy == null_accuracy:\n",
    "        print (\"model has the same accuracy with the null accuracy\")\n",
    "    else:\n",
    "        print (\"model is {0:.2f}% less accurate than null accuracy\".format((null_accuracy-accuracy)*100))\n",
    "    print (\"train and test time: {0:.2f}s\".format(train_test_time))\n",
    "    print (\"-\"*80)\n",
    "    return accuracy, train_test_time\n",
    "\n",
    "cvec = CountVectorizer()\n",
    "lr = LogisticRegression()\n",
    "n_features = np.arange(10000,100001,10000)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "names = [\"Logistic Regression\", \"Linear SVC\", \"LinearSVC with L1-based feature selection\",\"Multinomial NB\", \n",
    "         \"Bernoulli NB\", \"Ridge Classifier\", \"AdaBoost\", \"Perceptron\",\"Passive-Aggresive\", \"Nearest Centroid\"]\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    LinearSVC(),\n",
    "    Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False))),\n",
    "  ('classification', LinearSVC(penalty=\"l2\"))]),\n",
    "    MultinomialNB(),\n",
    "    BernoulliNB(),\n",
    "    RidgeClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    Perceptron(),\n",
    "    PassiveAggressiveClassifier(),\n",
    "    NearestCentroid()\n",
    "    ]\n",
    "zipped_clf = zip(names,classifiers)\n",
    "\n",
    "cvec = CountVectorizer()\n",
    "\n",
    "def classifier_comparator(vectorizer=cvec, n_features=10000, stop_words=None, ngram_range=(1, 1), classifier=zipped_clf):\n",
    "    result = []\n",
    "    vectorizer.set_params(stop_words=stop_words, max_features=n_features, ngram_range=ngram_range)\n",
    "    for n,c in classifier:\n",
    "        checker_pipeline = Pipeline([\n",
    "            ('vectorizer', vectorizer),\n",
    "            ('classifier', c)\n",
    "        ])\n",
    "        print \"Test result for {}\".format(n)\n",
    "        print c\n",
    "        clf_accuracy,tt_time = accuracy_summary(checker_pipeline, x_train, y_train, x_test, y_test)\n",
    "        result.append((n,clf_accuracy,tt_time))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test result for Logistic Regression\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "null accuracy: 50.15%\n",
      "accuracy score: 84.99%\n",
      "model is 34.83% more accurate than null accuracy\n",
      "train and test time: 463.34s\n",
      "--------------------------------------------------------------------------------\n",
      "Test result for Linear SVC\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "null accuracy: 50.15%\n",
      "accuracy score: 83.77%\n",
      "model is 33.62% more accurate than null accuracy\n",
      "train and test time: 909.62s\n",
      "--------------------------------------------------------------------------------\n",
      "Test result for LinearSVC with L1-based feature selection\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit...ax_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))])\n",
      "null accuracy: 50.15%\n",
      "accuracy score: 83.51%\n",
      "model is 33.35% more accurate than null accuracy\n",
      "train and test time: 940.38s\n",
      "--------------------------------------------------------------------------------\n",
      "Test result for Multinomial NB\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "null accuracy: 50.15%\n",
      "accuracy score: 83.26%\n",
      "model is 33.11% more accurate than null accuracy\n",
      "train and test time: 28.25s\n",
      "--------------------------------------------------------------------------------\n",
      "Test result for Bernoulli NB\n",
      "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "null accuracy: 50.15%\n",
      "accuracy score: 83.31%\n",
      "model is 33.15% more accurate than null accuracy\n",
      "train and test time: 29.16s\n",
      "--------------------------------------------------------------------------------\n",
      "Test result for Ridge Classifier\n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
      "        tol=0.001)\n",
      "null accuracy: 50.15%\n",
      "accuracy score: 84.86%\n",
      "model is 34.71% more accurate than null accuracy\n",
      "train and test time: 929.32s\n",
      "--------------------------------------------------------------------------------\n",
      "Test result for AdaBoost\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "null accuracy: 50.15%\n",
      "accuracy score: 69.63%\n",
      "model is 19.48% more accurate than null accuracy\n",
      "train and test time: 377.59s\n",
      "--------------------------------------------------------------------------------\n",
      "Test result for Perceptron\n",
      "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
      "      max_iter=None, n_iter=None, n_jobs=1, penalty=None, random_state=0,\n",
      "      shuffle=True, tol=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null accuracy: 50.15%\n",
      "accuracy score: 78.10%\n",
      "model is 27.94% more accurate than null accuracy\n",
      "train and test time: 32.63s\n",
      "--------------------------------------------------------------------------------\n",
      "Test result for Passive-Aggresive\n",
      "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "              fit_intercept=True, loss='hinge', max_iter=None, n_iter=None,\n",
      "              n_jobs=1, random_state=None, shuffle=True, tol=None,\n",
      "              verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null accuracy: 50.15%\n",
      "accuracy score: 80.16%\n",
      "model is 30.01% more accurate than null accuracy\n",
      "train and test time: 32.99s\n",
      "--------------------------------------------------------------------------------\n",
      "Test result for Nearest Centroid\n",
      "NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
      "null accuracy: 50.15%\n",
      "accuracy score: 69.63%\n",
      "model is 19.48% more accurate than null accuracy\n",
      "train and test time: 28.90s\n",
      "--------------------------------------------------------------------------------\n",
      "Wall time: 1h 2min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "unigram_result = classifier_comparator(n_features=100000,ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\numpy\\lib\\arraysetops.py:466: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n",
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has total 3527995 entries with 50.00% negative, 50.00% positive\n",
      "Test set has total 72000 entries with 50.02% negative, 49.98% positive\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train_amazon_longreview_clean.csv', index_col = 0, encoding = \"ISO-8859-1\")\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "x = df.clean_text\n",
    "y = df.target\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "SEED = 2000\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.02, random_state=SEED)\n",
    "\n",
    "print (\"Train set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(x_train),\n",
    "                                                                             (len(x_train[y_train == 0]) / (len(x_train)*1.))*100,\n",
    "                                                                            (len(x_train[y_train == 1]) / (len(x_train)*1.))*100))\n",
    "print (\"Test set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(x_test),\n",
    "                                                                             (len(x_test[y_test == 0]) / (len(x_test)*1.))*100,\n",
    "                                                                            (len(x_test[y_test == 1]) / (len(x_test)*1.))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test result for Logistic Regression\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "null accuracy: 50.02%\n",
      "accuracy score: 88.82%\n",
      "model is 38.80% more accurate than null accuracy\n",
      "train and test time: 7783.65s\n",
      "--------------------------------------------------------------------------------\n",
      "Test result for Linear SVC\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "null accuracy: 50.02%\n",
      "accuracy score: 85.29%\n",
      "model is 35.28% more accurate than null accuracy\n",
      "train and test time: 2512.68s\n",
      "--------------------------------------------------------------------------------\n",
      "Test result for LinearSVC with L1-based feature selection\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit...ax_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))])\n",
      "null accuracy: 50.02%\n",
      "accuracy score: 84.70%\n",
      "model is 34.68% more accurate than null accuracy\n",
      "train and test time: 2451.89s\n",
      "--------------------------------------------------------------------------------\n",
      "Test result for Multinomial NB\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "null accuracy: 50.02%\n",
      "accuracy score: 82.91%\n",
      "model is 32.90% more accurate than null accuracy\n",
      "train and test time: 484.22s\n",
      "--------------------------------------------------------------------------------\n",
      "Test result for Bernoulli NB\n",
      "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "null accuracy: 50.02%\n",
      "accuracy score: 82.10%\n",
      "model is 32.08% more accurate than null accuracy\n",
      "train and test time: 543.27s\n",
      "--------------------------------------------------------------------------------\n",
      "Test result for Ridge Classifier\n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
      "        tol=0.001)\n",
      "null accuracy: 50.02%\n",
      "accuracy score: 88.60%\n",
      "model is 38.58% more accurate than null accuracy\n",
      "train and test time: 3567.99s\n",
      "--------------------------------------------------------------------------------\n",
      "Test result for AdaBoost\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "null accuracy: 50.02%\n",
      "accuracy score: 77.82%\n",
      "model is 27.80% more accurate than null accuracy\n",
      "train and test time: 3558.65s\n",
      "--------------------------------------------------------------------------------\n",
      "Test result for Perceptron\n",
      "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
      "      max_iter=None, n_iter=None, n_jobs=1, penalty=None, random_state=0,\n",
      "      shuffle=True, tol=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null accuracy: 50.02%\n",
      "accuracy score: 85.58%\n",
      "model is 35.56% more accurate than null accuracy\n",
      "train and test time: 394.55s\n",
      "--------------------------------------------------------------------------------\n",
      "Test result for Passive-Aggresive\n",
      "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "              fit_intercept=True, loss='hinge', max_iter=None, n_iter=None,\n",
      "              n_jobs=1, random_state=None, shuffle=True, tol=None,\n",
      "              verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wmj51\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null accuracy: 50.02%\n",
      "accuracy score: 84.33%\n",
      "model is 34.32% more accurate than null accuracy\n",
      "train and test time: 377.86s\n",
      "--------------------------------------------------------------------------------\n",
      "Test result for Nearest Centroid\n",
      "NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
      "null accuracy: 50.02%\n",
      "accuracy score: 59.46%\n",
      "model is 9.44% more accurate than null accuracy\n",
      "train and test time: 381.28s\n",
      "--------------------------------------------------------------------------------\n",
      "Wall time: 6h 7min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "unigram_result = classifier_comparator(n_features=100000,ngram_range=(1,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
